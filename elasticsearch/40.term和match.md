### `term` 和 `match` 总结

在实际的项目查询中，`term`和`match` 是最常用的两个查询，而经常搞不清两者有什么区别，趁机总结有空总结下。

#### `term`用法

先看看term的定义，term是代表完全匹配，也就是精确查询，搜索前不会再对搜索词进行分词拆解。

这里通过例子来说明，先存放一些数据：



```json
{
    "title": "love China",
    "content": "people very love China",
    "tags": ["China", "love"]
}
{
    "title": "love HuBei",
    "content": "people very love HuBei",
    "tags": ["HuBei", "love"]
}
```

来使用`term` 查询下：



```json
{
  "query": {
    "term": {
      "title": "love"
    }
  }
}
```

结果是，上面的两条数据都能查询到：



```json
{
  "took": 1,
  "timed_out": false,
  "_shards": {
    "total": 5,
    "successful": 5,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": 2,
    "max_score": 0.6931472,
    "hits": [
      {
        "_index": "test",
        "_type": "doc",
        "_id": "8",
        "_score": 0.6931472,
        "_source": {
          "title": "love HuBei",
          "content": "people very love HuBei",
          "tags": ["HuBei","love"]
        }
      },
      {
        "_index": "test",
        "_type": "doc",
        "_id": "7",
        "_score": 0.6931472,
        "_source": {
          "title": "love China",
          "content": "people very love China",
          "tags": ["China","love"]
        }
      }
    ]
  }
}
```

发现，title里有关love的关键字都查出来了，但是我只想精确匹配 `love China`这个，按照下面的写法看看能不能查出来：



```json
{
  "query": {
    "term": {
      "title": "love China"
    }
  }
}
```

执行发现无数据，从概念上看，term属于精确匹配，只能查单个词。我想用term匹配多个词怎么做？可以使用`terms`来：



```json
{
  "query": {
    "terms": {
      "title": ["love", "China"]
    }
  }
}
```

查询结果为：



```json
{
  "took": 1,
  "timed_out": false,
  "_shards": {
    "total": 5,
    "successful": 5,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": 2,
    "max_score": 0.6931472,
    "hits": [
      {
        "_index": "test",
        "_type": "doc",
        "_id": "8",
        "_score": 0.6931472,
        "_source": {
          "title": "love HuBei",
          "content": "people very love HuBei",
          "tags": ["HuBei","love"]
        }
      },
      {
        "_index": "test",
        "_type": "doc",
        "_id": "7",
        "_score": 0.6931472,
        "_source": {
          "title": "love China",
          "content": "people very love China",
          "tags": ["China","love"]
        }
      }
    ]
  }
}
```

发现全部查询出来，为什么？因为terms里的`[ ]` 多个是或者的关系，只要满足其中一个词就可以。想要通知满足两个词的话，就得使用bool的must来做，如下：



```json
{
  "query": {
    "bool": {
      "must": [
        {
          "term": {
            "title": "love"
          }
        },
        {
          "term": {
            "title": "china"
          }
        }
      ]
    }
  }
}
```

可以看到，我们上面使用`china`是小写的。当使用的是大写的`China` 我们进行搜索的时候，发现搜不到任何信息。这是为什么了？title这个词在进行存储的时候，进行了分词处理。我们这里使用的是默认的分词处理器进行了分词处理。我们可以看看如何进行分词处理的？

#### 分词处理器



```bash
GET test/_analyze
{
  "text" : "love China"
}
```

结果为：



```json
{
  "tokens": [
    {
      "token": "love",
      "start_offset": 0,
      "end_offset": 4,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "china",
      "start_offset": 5,
      "end_offset": 10,
      "type": "<ALPHANUM>",
      "position": 1
    }
  ]
}
```

分析出来的为`love`和`china`的两个词。而`term`只能完完整整的匹配上面的词，不做任何改变的匹配。所以，我们使用`China`这样的方式进行的查询的时候，就会失败。稍后会有一节专门讲解分词器。

#### `match` 用法

先用 `love China`来匹配。



```json
GET test/doc/_search
{
  "query": {
    "match": {
      "title": "love China"
    }
  }
}
```

结果是：



```json
{
  "took": 1,
  "timed_out": false,
  "_shards": {
    "total": 5,
    "successful": 5,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": 2,
    "max_score": 1.3862944,
    "hits": [
      {
        "_index": "test",
        "_type": "doc",
        "_id": "7",
        "_score": 1.3862944,
        "_source": {
          "title": "love China",
          "content": "people very love China",
          "tags": [
            "China",
            "love"
          ]
        }
      },
      {
        "_index": "test",
        "_type": "doc",
        "_id": "8",
        "_score": 0.6931472,
        "_source": {
          "title": "love HuBei",
          "content": "people very love HuBei",
          "tags": [
            "HuBei",
            "love"
          ]
        }
      }
    ]
  }
}
```

发现两个都查出来了，为什么？因为match进行搜索的时候，会先进行分词拆分，拆完后，再来匹配，上面两个内容，他们title的词条为： `love china hubei` ，我们搜索的为`love China` 我们进行分词处理得到为`love china` ，并且属于或的关系，只要任何一个词条在里面就能匹配到。如果想 `love` 和 `China` 同时匹配到的话，怎么做？使用 `match_phrase`

#### `match_phrase` 用法

`match_phrase` 称为短语搜索，要求所有的分词必须同时出现在文档中，同时位置必须紧邻一致。



```json
GET test/doc/_search
{
  "query": {
    "match_phrase": {
      "title": "love china"
    }
  }
}
```

结果为：



```json
{
  "took": 5,
  "timed_out": false,
  "_shards": {
    "total": 5,
    "successful": 5,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": 1,
    "max_score": 1.3862944,
    "hits": [
      {
        "_index": "test",
        "_type": "doc",
        "_id": "7",
        "_score": 1.3862944,
        "_source": {
          "title": "love China",
          "content": "people very love China",
          "tags": [
            "China",
            "love"
          ]
        }
      }
    ]
  }
}
```

这次好像符合我们的需求了，结果只出现了一条记录。



作者：f22448cd5541
链接：https://www.jianshu.com/p/d5583dff4157
来源：简书
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



# text类型

```json
1:支持分词，全文检索,支持模糊、精确查询,不支持聚合,排序操作;
2:test类型的最大支持的字符长度无限制,适合大字段存储；
使用场景：
    存储全文搜索数据, 例如: 邮箱内容、地址、代码块、博客文章内容等。
    默认结合standard analyzer(标准解析器)对文本进行分词、倒排索引。
    默认结合标准分析器进行词命中、词频相关度打分。
```

# keyword

```json
1:不进行分词，直接索引,支持模糊、支持精确匹配，支持聚合、排序操作。
2:keyword类型的最大支持的长度为——32766个UTF-8类型的字符,可以通过设置ignore_above指定自持字符长度，超过给定长度后的数据将不被索引，无法通过term精确匹配检索返回结果。

使用场景：
存储邮箱号码、url、name、title，手机号码、主机名、状态码、邮政编码、标签、年龄、性别等数据。
用于筛选数据(例如: select * from x where status='open')、排序、聚合(统计)。
直接将完整的文本保存到倒排索引中。
```

# Dynamic

dynamic属性：默认值为true，允许动态地向文档类型中加入新的字段。推荐设置为false，禁止向文档中添加字段，这样，文档类型的所有字段必须在索引映射的properties属性中显式定义，在properties字段中未定义的字段都将会ElasticSearch忽略。
dynamic设置为ture：默认值，新增加的字段被添加到索引映射中；
dynamic设置为false：新增加的字段会被忽略；
dynamic设置为strict：当向文档中新增字段时，ElasticSearch引擎抛出异常；

```json
# index
```

index定义字段的分析类型以及检索方式，控制字段值是否被索引.他可以设置成 true 或者 false。没有被索引的字段将无法搜索

如果是no，则无法通过检索查询到该字段；
如果设置为not_analyzed则会将整个字段存储为关键词，常用于汉字短语、邮箱等复杂的字符串；
如果设置为analyzed则将会通过默认的standard分析器进行分析

```
# 集群分片
```

Elasticsearch 有一个硬编码限制，单个分片内的文档总数不得超过 2147483519 个。
一般来说这个限制在日志场景下是不太会触发的，但是如果做 TSDB 用，则需要多加注意！

```
ES更新到5版本后，取消了 string 数据类型，代替它的是 keyword 和 text 数据类型.那么 text 和keyword有什么区别呢？
# 添加数据
使用bulk往es数据库中批量添加一些document
```

```json
POST /book/novel/_bulk
{"index": {"_id": 1}}
{"name": "Gone with the Wind", "author": "Margaret Mitchell", "date": "2018-01-01"}
{"index": {"_id": 2}}
{"name": "Robinson Crusoe", "author": "Daniel Defoe", "date": "2018-01-02"}
{"index": {"_id": 3}}
{"name": "Pride and Prejudice", "author": "Jane Austen", "date": "2018-01-01"}
{"index": {"_id": 4}}
{"name": "Jane Eyre", "author": "Charlotte Bronte", "date": "2018-01-02"}
```


\# 查看mapping 发现name、author的type是text， 还有个field是keyword，keyword的type是keyword： ![](https://img2018.cnblogs.com/blog/794174/202001/794174-20200110173842134-130158795.png) # 查询 使用term查询某个小说：

```json
GET book/novel/_search
{
  "query": {
    "constant_score": {
      "filter": {
          "term": {
          "name": "Gone with the Wind"
          }
      },
      "boost": 1.2
    }
  }
}
```

结果是什么也没有查到： ![](https://img2018.cnblogs.com/blog/794174/202001/794174-20200110174004507-231647388.png)  然后使用name的keyword查询：

```json
GET book/novel/_search
{
  "query": {
    "constant_score": {
      "filter": {
          "term": {
          "name.keyword": "Gone with the Wind"
          }
      },
      "boost": 1.2
    }
  }
}
```

可以查询到一条数据： ![](https://img2018.cnblogs.com/blog/794174/202001/794174-20200110174012973-1391506656.png) 

# 实验 使用name不能查到，而使用name.keyword可以查到，我们可以通过下面的实验来判断： 使用name进行分词的时候，结果会有4个词出来： ![](https://img2018.cnblogs.com/blog/794174/202001/794174-20200110174103797-238415295.png)  使用name.keyword进行分词的时候，结果只有一个词出来： ![](C:/Users/wb-st772099/AppData/Roaming/Typora/typora-user-images/image-20200910145420179.png) # 结论 text类型：会分词，先把对象进行分词处理，然后再再存入到es中。 当使用多个单词进行查询的时候，当然查不到已经分词过的内容！ keyword：不分词，没有把es中的对象进行分词处理，而是存入了整个对象！ 这时候当然可以进行完整地查询！默认是256个字符！

