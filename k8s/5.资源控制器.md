### rs

```yaml
apiVersion: extensions/v1beta1
kind: ReplicaSet
metadata:
  name: frontend
spec:
  replicas: 2
  selector:    ##选择标签
    matchLabels:    #匹配标签
      app: frontend   #标签名
  template:    #模板
    metadata:
      labels:
        app: frontend
    spec:
      containers:
      - name: nginx
        image: nginx
        env:   #注入环境变量
        - name: GET_HOST_FROM
          value: dns
        ports:
        - containerPort: 80
```

```yaml
[root@master01 myapp]# vim frontend.yaml
[root@master01 myapp]# kubectl get pod
NAME                    READY   STATUS    RESTARTS   AGE
myapp-pod               1/1     Running   0          23h
readiness-httpget-pod   1/1     Running   0          22h
[root@master01 myapp]# kubectl delete pod --all
pod "myapp-pod" deleted
pod "readiness-httpget-pod" deleted
[root@master01 myapp]# kubectl get pod
No resources found.
[root@master01 myapp]# kubectl get svc
NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1        <none>        443/TCP   33h
mydb         ClusterIP   10.96.201.14     <none>        80/TCP    22h
myservice    ClusterIP   10.110.163.186   <none>        80/TCP    22h
[root@master01 myapp]# kubectl delete svc mydb myservice
service "mydb" deleted
service "myservice" deleted
[root@master01 myapp]# kubectl get svc
NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   33h
[root@master01 myapp]# kubectl get deployment
No resources found.
# 上面为清空环境
[root@master01 myapp]# kubectl create -f  frontend.yaml 
replicaset.extensions/frontend created
# 启动后会创建两个pod，并由rs控制器维持在两个pod，删除了会重新创建
[root@master01 myapp]# kubectl get pod
NAME             READY   STATUS              RESTARTS   AGE
frontend-97bmm   0/1     ContainerCreating   0          10s
frontend-h2zkk   0/1     ContainerCreating   0          10s
# 删除会维持为两个副本，重新创建两个pod
[root@master01 myapp]# kubectl delete pod --all
pod "frontend-97bmm" deleted
pod "frontend-h2zkk" deleted
[root@master01 myapp]# kubectl get pod
NAME             READY   STATUS    RESTARTS   AGE
frontend-b94sl   1/1     Running   0          20s
frontend-ft92m   1/1     Running   0          20s
# 查询pod和pod的labels
[root@master01 myapp]# kubectl get pod --show-labels
NAME             READY   STATUS    RESTARTS   AGE   LABELS
frontend-b94sl   1/1     Running   0          57s   app=frontend
frontend-ft92m   1/1     Running   0          57s   app=frontend
# 更改pod的label
[root@master01 myapp]# kubectl label pod frontend-b94sl app=frontend1 --overwrite
pod/frontend-b94sl labeled
# 会发现标签改变了，会新起一个pod
[root@master01 myapp]# kubectl get pod --show-labels
NAME             READY   STATUS    RESTARTS   AGE     LABELS
frontend-b94sl   1/1     Running   0          2m16s   app=frontend1
frontend-ft92m   1/1     Running   0          2m16s   app=frontend
frontend-rmr9j   1/1     Running   0          16s     app=frontend
# 删除rs 不会的pod app=frountend1 对应的pod，这里删错了   
[root@master01 myapp]# kubectl delete pod --all
pod "frontend-b94sl" deleted
pod "frontend-ft92m" deleted
pod "frontend-rmr9j" deleted
[root@master01 myapp]# kubectl get pod --show-labels
NAME             READY   STATUS              RESTARTS   AGE   LABELS
frontend-jf8ql   0/1     ContainerCreating   0          14s   app=frontend
frontend-n7rpz   0/1     ContainerCreating   0          14s   app=frontend
[root@master01 myapp]# kubectl get rs
NAME       DESIRED   CURRENT   READY   AGE
frontend   2         2         2       7m9s

```

### deployment

```
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: hub.st.com/library/mynginx:v1
        ports:
        - containerPort: 80
```

扩容

```
kubectl scale deployment nginx-deployment --replicas 10
```

如果集群支持 horizontal pod autoscaling 的话，还可以为Deployment设置自动扩展：

```
kubectl autoscale deployment nginx-deployment --min=10 --max=15 --cpu-percent=80
```

更新镜像也比较简单:

```
kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1
```

回滚：

```shell
kubectl rollout undo deployment/nginx-deployment

# 回滚到指定版本
kubectl rollout undo deployment/nginx-deployment --to-revision=3
```

回滚查看状态

```shell
kubectl rollout status deployment/nginx-deployment

# 也可以通过$?去查询，返回为0表示成功
[root@master01 myapp]# echo $?
0

```

### DaemonSet

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: deamonset-example
  labels:
    app: daemonset
spec:
  selector:
    matchLabels:
      name: deamonset-example
  template:
    metadata:
      labels:
        name: deamonset-example
    spec:
      containers:
      - name: daemonset-example
        image: hub.st.com/mynginx:v1
```

### job

#### cronjob Spec

- spec.template格式同Pod
- RestartPolicy仅支持Never或OnFailure
- 单个Pod时，默认Pod成功运行后Job即结束
- `.spec.completions`标志Job结束需要成功运行的Pod个数，默认为1
- `.spec.parallelism`标志并行运行的Pod的个数，默认为1
- `spec.activeDeadlineSeconds`标志失败Pod的重试最大时间，超过这个时间

#### Bare Pods

所谓Bare Pods是指直接用PodSpec来创建的Pod（即不在ReplicaSets或者ReplicationController的管理之下的Pods）。这些Pod在Node重启后不会自动重启，但Job则会创建新的Pod继续任务。所以，推荐使用Job来替代Bare Pods，即便是应用只需要一个Pod。

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: pi
spec:
  template:
    metadata:
      name: pi
    spec:
      containers:
      - name: pi
        image: perl
        command: ["perl",  "-Mbignum=bpi", "-wle", "print bpi(2000)"]
      restartPolicy: Never
```

```yaml
[root@master01 myapp]# kubectl get pod -o wide
NAME                      READY   STATUS      RESTARTS   AGE     IP            NODE     NOMINATED NODE   READINESS GATES
deamonset-example-l9tkp   1/1     Running     0          6m56s   10.244.1.28   node01   <none>           <none>
deamonset-example-zlmrp   1/1     Running     0          7m29s   10.244.2.29   node02   <none>           <none>
# 表示计算完成了
pi-qw8qk                  0/1     Completed   0          4m49s   10.244.1.29   node01   <none>           <none>
[root@master01 myapp]# kubectl get job
NAME   COMPLETIONS   DURATION   AGE
pi     1/1           52s        8m22s
[root@master01 myapp]# kubectl logs pi-qw8qk
3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679821480865132823066470938446095505822317253594081284811174502841027019385211055596446229489549303819644288109756659334461284756482337867831652712019091456485669234603486104543266482133936072602491412737245870066063155881748815209209628292540917153643678925903600113305305488204665213841469519415116094330572703657595919530921861173819326117931051185480744623799627495673518857527248912279381830119491298336733624406566430860213949463952247371907021798609437027705392171762931767523846748184676694051320005681271452635608277857713427577896091736371787214684409012249534301465495853710507922796892589235420199561121290219608640344181598136297747713099605187072113499999983729780499510597317328160963185950244594553469083026425223082533446850352619311881710100031378387528865875332083814206171776691473035982534904287554687311595628638823537875937519577818577805321712268066130019278766111959092164201989380952572010654858632788659361533818279682303019520353018529689957736225994138912497217752834791315155748572424541506959508295331168617278558890750983817546374649393192550604009277016711390098488240128583616035637076601047101819429555961989467678374494482553797747268471040475346462080466842590694912933136770289891521047521620569660240580381501935112533824300355876402474964732639141992726042699227967823547816360093417216412199245863150302861829745557067498385054945885869269956909272107975093029553211653449872027559602364806654991198818347977535663698074265425278625518184175746728909777727938000816470600161452491921732172147723501414419735685481613611573525521334757418494684385233239073941433345477624168625189835694855620992192221842725502542568876717904946016534668049886272327917860857843838279679766814541009538837863609506800642251252051173929848960841284886269456042419652850222106611863067442786220391949450471237137869609563643719172874677646575739624138908658326459958133904780275901
```

### cron job

#### CronJob Spec

- `.spec.schedule`：**调度**，必需字段，指定任务运行周期，格式同 [Cron](https://en.wikipedia.org/wiki/Cron)

- `.spec.jobTemplate`：**Job 模板**，必需字段，指定需要运行的任务，格式同 [Job](https://www.bookstack.cn/read/kubernetes-handbook-201910/concepts-job.md)

- `.spec.startingDeadlineSeconds` ：**启动 Job 的期限（秒级别）**，该字段是可选的。如果因为任何原因而错过了被调度的时间，那么错过执行时间的 Job 将被认为是失败的。如果没有指定，则没有期限

- `.spec.concurrencyPolicy`：**并发策略**，该字段也是可选的。它指定了如何处理被 Cron Job 创建的 Job 的并发执行。只允许指定下面策略中的一种：

  - `Allow`（默认）：允许并发运行 Job
  - `Forbid`：禁止并发运行，如果前一个还没有完成，则直接跳过下一个
  - `Replace`：取消当前正在运行的 Job，用一个新的来替换

  注意，当前策略只能应用于同一个 Cron Job 创建的 Job。如果存在多个 Cron Job，它们创建的 Job 之间总是允许并发运行。

- `.spec.suspend` ：**挂起**，该字段也是可选的。如果设置为 `true`，后续所有执行都会被挂起。它对已经开始执行的 Job 不起作用。默认值为 `false`。

- `.spec.successfulJobsHistoryLimit` 和 `.spec.failedJobsHistoryLimit` ：**历史限制**，是可选的字段。它们指定了可以保留多少完成和失败的 Job。

  默认情况下，它们分别设置为 `3` 和 `1`。设置限制的值为 `0`，相关类

```yaml
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: hello
spec:
  schedule: "*/1 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: hello
            image: busybox
            args:
            - /bin/sh
            - -c
            - date; echo Hello from the Kubernetes cluster
          restartPolicy: OnFailure
```

```shell
[root@master01 myapp]# kubectl get job
NAME               COMPLETIONS   DURATION   AGE
hello-1594828980   1/1           6s         2m25s
hello-1594829040   1/1           17s        85s
hello-1594829100   1/1           16s        25s
[root@master01 myapp]# kubectl get pod -w
NAME                     READY   STATUS      RESTARTS   AGE
hello-1594828980-xv5bj   0/1     Completed   0          2m34s
hello-1594829040-jx67j   0/1     Completed   0          94s
hello-1594829100-zzcz4   0/1     Completed   0          34s
^C[root@master01 myapp]# kubectl log hello-1594828980-xv5bj
log is DEPRECATED and will be removed in a future version. Use logs instead.
Wed Jul 15 16:03:14 UTC 2020
Hello from the Kubernetes cluster

```

